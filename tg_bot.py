import logging
import cv2
import numpy as np
from PIL import Image
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
import os

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–î–û–õ–ñ–ù–ê —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –æ–±—É—á–µ–Ω–∏–µ–º!) ---
MODEL_PATH = 'best_model.keras'
IMG_SIZE = (128, 128)  # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ (224, 224), –µ—Å–ª–∏ –æ–±—É—á–∞–ª–∏ –Ω–∞ —Ç–∞–∫–æ–º —Ä–∞–∑–º–µ—Ä–µ
model = load_model(MODEL_PATH)

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –ª–∏—Ü ---
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# --- –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ---
def predict_mask(image):
    # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    image = image.resize(IMG_SIZE)
    image_array = img_to_array(image)
    image_array = image_array / 255.0
    image_array = np.expand_dims(image_array, axis=0)

    # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    prediction = model.predict(image_array, verbose=0)
    class_idx = np.argmax(prediction[0])
    confidence = np.max(prediction[0])

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    labels = ['–° –º–∞—Å–∫–æ–π', '–ë–µ–∑ –º–∞—Å–∫–∏']
    return labels[class_idx], confidence

# --- –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è Telegram ---
async def start(update: Update, context: CallbackContext):
    await update.message.reply_text('–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ñ–æ—Ç–æ –ª–∏—Ü–∞, –∏ —è –æ–ø—Ä–µ–¥–µ–ª—é, –µ—Å—Ç—å –ª–∏ –Ω–∞ –Ω—ë–º –º–∞—Å–∫–∞.')

async def handle_photo(update: Update, context: CallbackContext):
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ
        photo_file = await update.message.photo[-1].get_file()
        await photo_file.download_to_drive('user_photo.jpg')

        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = Image.open('user_photo.jpg').convert('RGB')
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL –≤ OpenCV —Ñ–æ—Ä–º–∞—Ç
        image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)
        
        # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –ª–∏—Ü–∞
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))
        
        if len(faces) == 0:
            await update.message.reply_text("‚ùå –õ–∏—Ü–æ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –±–æ–ª–µ–µ —á—ë—Ç–∫–æ–µ —Ñ–æ—Ç–æ –ª–∏—Ü–∞.")
            return
        
        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤–æ–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –ª–∏—Ü–æ (—Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ)
        faces = sorted(faces, key=lambda x: x[2]*x[3], reverse=True)  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–ª–æ—â–∞–¥–∏
        x, y, w, h = faces[0]
        
        # –í—ã—Ä–µ–∑–∞–µ–º –æ–±–ª–∞—Å—Ç—å –ª–∏—Ü–∞ —Å –Ω–µ–±–æ–ª—å—à–∏–º –∑–∞–ø–∞—Å–æ–º
        padding = 20
        x1 = max(0, x - padding)
        y1 = max(0, y - padding)
        x2 = min(image_cv.shape[1], x + w + padding)
        y2 = min(image_cv.shape[0], y + h + padding)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ PIL Image
        face_roi = image.crop((x1, y1, x2, y2))
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞—Å–∫—É
        label, confidence = predict_mask(face_roi)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if confidence < 0.6:
            confidence_note = " (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)"
        elif confidence < 0.8:
            confidence_note = " (—Å—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)"
        else:
            confidence_note = " (–≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)"
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
        response = f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {label}{confidence_note}\n‚úÖ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%}\nüë§ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: {len(faces)}"
        
        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ —Ñ–æ—Ç–æ —Å –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–º –ª–∏—Ü–æ–º
        if len(faces) <= 3:  # –ï—Å–ª–∏ –ª–∏—Ü –Ω–µ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ
            # –†–∏—Å—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏ –≤–æ–∫—Ä—É–≥ –ª–∏—Ü
            for (fx, fy, fw, fh) in faces[:3]:  # –ú–∞–∫—Å–∏–º—É–º 3 –ª–∏—Ü–∞
                cv2.rectangle(image_cv, (fx, fy), (fx+fw, fy+fh), (0, 255, 0), 2)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ —Ñ–æ—Ç–æ
            processed_path = 'user_photo_processed.jpg'
            cv2.imwrite(processed_path, image_cv)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ç–æ —Å –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –ª–∏—Ü–∞–º–∏
            with open(processed_path, 'rb') as photo:
                await update.message.reply_photo(photo, caption=response)
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            os.remove(processed_path)
        else:
            await update.message.reply_text(response)
            
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ: {e}")
        await update.message.reply_text("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ç–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
    
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        if os.path.exists('user_photo.jpg'):
            os.remove('user_photo.jpg')

# --- –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ---
def main():
    # –í–ê–ñ–ù–û: –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω!
    TOKEN = "8230459480:AAHP99YpYbFRJ3IkTyImD1x8_i0_GKpvmwc"

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ –±–æ—Ç–∞
    application = Application.builder().token(TOKEN).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))

    application.run_polling()

if __name__ == '__main__':
    main()