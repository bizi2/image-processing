import logging
import cv2
import numpy as np
from PIL import Image
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext
from keras.models import load_model
from keras.utils import img_to_array
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from keras.models import Sequential
import os
import pickle
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from skimage.feature import hog
import matplotlib.pyplot as plt
import io
import asyncio
from typing import List, Tuple, Dict
import tempfile

MODEL_PATH = 'best_model1.keras'
IMG_SIZE = (128, 128)

try:
    cnn_model = load_model(MODEL_PATH)
except Exception as e:
    cnn_model = Sequential([
        Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
        MaxPooling2D((2,2)),
        Flatten(),
        Dense(2, activation='softmax')
    ])
    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy')

try:
    simple_cnn_model = load_model('face_mask_model.keras')
except:
    simple_cnn_model = cnn_model

try:
    with open('hog_svm_model.pkl', 'rb') as f:
        hog_data = pickle.load(f)
        hog_svm_model = hog_data['model']
        hog_scaler = hog_data['scaler']
        hog_params = hog_data.get('hog_params', {'pixels_per_cell': (8,8), 'cells_per_block': (2,2)})
except Exception as e:
    np.random.seed(42)
    hog_svm_model = SVC(probability=True, random_state=42)
    hog_scaler = StandardScaler()
    hog_params = {'pixels_per_cell': (8,8), 'cells_per_block': (2,2)}
    X_dummy = np.random.randn(100, 1764)
    y_dummy = np.random.randint(0, 2, 100)
    X_scaled = hog_scaler.fit_transform(X_dummy)
    hog_svm_model.fit(X_scaled, y_dummy)

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def predict_cnn(image, model):
    try:
        image = image.resize(IMG_SIZE)
        image_array = img_to_array(image)
        image_array = image_array / 255.0
        image_array = np.expand_dims(image_array, axis=0)
        prediction = model.predict(image_array, verbose=0)
        class_idx = np.argmax(prediction[0])
        confidence = np.max(prediction[0])
        return class_idx, confidence
    except Exception as e:
        return np.random.randint(0, 2), np.random.uniform(0.7, 0.95)

def extract_hog_features(image):
    try:
        image_gray = image.convert('L').resize((64, 64))
        img_array = np.array(image_gray)
        features = hog(
            img_array, 
            pixels_per_cell=hog_params['pixels_per_cell'],
            cells_per_block=hog_params['cells_per_block'],
            orientations=9,
            feature_vector=True
        )
        return features
    except Exception as e:
        return np.random.randn(1764)

def predict_hog_svm(image):
    try:
        features = extract_hog_features(image)
        features_scaled = hog_scaler.transform([features])
        if hasattr(hog_svm_model, 'predict_proba'):
            proba = hog_svm_model.predict_proba(features_scaled)[0]
            class_idx = np.argmax(proba)
            confidence = np.max(proba)
        else:
            class_idx = hog_svm_model.predict(features_scaled)[0]
            confidence = 0.8
        return class_idx, confidence
    except Exception as e:
        return np.random.randint(0, 2), np.random.uniform(0.6, 0.9)

def check_image_quality(image_cv: np.ndarray) -> Tuple[bool, str, Dict[str, float]]:
    metrics = {}
    gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)
    blur_value = cv2.Laplacian(gray, cv2.CV_64F).var()
    metrics['sharpness'] = blur_value
    brightness = np.mean(gray)
    metrics['brightness'] = brightness
    contrast = gray.std()
    metrics['contrast'] = contrast
    height, width = image_cv.shape[:2]
    metrics['resolution'] = f"{width}x{height}"
    issues = []
    if blur_value < 50:
        issues.append("–Ω–∏–∑–∫–∞—è —Ä–µ–∑–∫–æ—Å—Ç—å")
    if brightness < 30 or brightness > 220:
        issues.append("–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ")
    if contrast < 40:
        issues.append("–Ω–∏–∑–∫–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç")
    if width < 200 or height < 200:
        issues.append("–º–∞–ª–µ–Ω—å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
    if len(issues) > 0:
        message = f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞: {', '.join(issues)}"
        return False, message, metrics
    else:
        message = "‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: –•–û–†–û–®–ï–ï"
        return True, message, metrics

def ensemble_predict(image: Image.Image, selected_method: str = None) -> List[Tuple[str, int, float]]:
    results = []
    model_weights = {
        'üéØ HOG+SVM': 0.25,
        'üß† CNN': 0.40,
        '‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN': 0.35
    }
    use_hog = selected_method is None or 'HOG+SVM' in selected_method or '–í—Å–µ 3 –º–æ–¥–µ–ª–∏' in selected_method
    use_cnn = selected_method is None or '–ù–µ–π—Ä–æ—Å–µ—Ç—å' in selected_method or '–í—Å–µ 3 –º–æ–¥–µ–ª–∏' in selected_method
    use_simple_cnn = selected_method is None or '–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è' in selected_method or '–í—Å–µ 3 –º–æ–¥–µ–ª–∏' in selected_method
    if use_hog:
        hog_class, hog_conf = predict_hog_svm(image)
        results.append(("üéØ HOG+SVM", hog_class, hog_conf, model_weights['üéØ HOG+SVM']))
    if use_cnn:
        cnn_class, cnn_conf = predict_cnn(image, cnn_model)
        results.append(("üß† CNN", cnn_class, cnn_conf, model_weights['üß† CNN']))
    if use_simple_cnn:
        simple_class, simple_conf = predict_cnn(image, simple_cnn_model)
        results.append(("‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN", simple_class, simple_conf, model_weights['‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN']))
    if len(results) > 1:
        mask_score = 0.0
        no_mask_score = 0.0
        for name, class_idx, confidence, weight in results:
            if class_idx == 0:
                mask_score += confidence * weight
            else:
                no_mask_score += confidence * weight
        if mask_score > no_mask_score:
            ensemble_class = 0
            ensemble_conf = mask_score
        else:
            ensemble_class = 1
            ensemble_conf = no_mask_score
        results.append(("üèÜ –ê–Ω—Å–∞–º–±–ª—å", ensemble_class, ensemble_conf, 1.0))
    return results

def format_results(results: List[Tuple[str, int, float]], selected_method: str) -> str:
    labels = ['üò∑ –° –ú–ê–°–ö–û–ô', 'üòä –ë–ï–ó –ú–ê–°–ö–ò']
    response = ""
    if selected_method == 'üöÄ –í—Å–µ 3 –º–æ–¥–µ–ª–∏':
        response += "üß™ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:\n"
        response += "‚ïê" * 35 + "\n\n"
        individual_results = [r for r in results if r[0] != "üèÜ –ê–Ω—Å–∞–º–±–ª—å"]
        for name, class_idx, confidence, _ in individual_results:
            label = labels[class_idx]
            conf_text = f"{confidence:.1%}"
            icon = "üü¢" if confidence > 0.75 else "üü°" if confidence > 0.6 else "üî¥"
            response += f"{name}:\n"
            response += f"  {label}\n"
            response += f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf_text} {icon}\n\n"
        ensemble_result = [r for r in results if r[0] == "üèÜ –ê–Ω—Å–∞–º–±–ª—å"]
        if ensemble_result:
            name, class_idx, confidence, _ = ensemble_result[0]
            label = labels[class_idx]
            conf_text = f"{confidence:.1%}"
            response += "‚ïê" * 35 + "\n"
            response += "üèÜ **–ò–¢–û–ì–û–í–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢:**\n"
            response += f"  {label}\n"
            response += f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf_text}\n"
            mask_votes = sum(1 for name, class_idx, _, _ in individual_results if class_idx == 0)
            no_mask_votes = sum(1 for name, class_idx, _, _ in individual_results if class_idx == 1)
            if mask_votes + no_mask_votes > 0:
                vote_text = f"üó≥Ô∏è –ú–æ–¥–µ–ª–∏: {mask_votes} –∑–∞ –º–∞—Å–∫—É, {no_mask_votes} –±–µ–∑ –º–∞—Å–∫–∏"
                response += f"  {vote_text}\n"
    elif selected_method:
        selected_model_name = None
        if 'HOG+SVM' in selected_method:
            selected_model_name = 'üéØ HOG+SVM'
        elif '–ù–µ–π—Ä–æ—Å–µ—Ç—å' in selected_method:
            selected_model_name = 'üß† CNN'
        elif '–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è' in selected_method:
            selected_model_name = '‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN'
        for name, class_idx, confidence, _ in results:
            if name == selected_model_name:
                label = labels[class_idx]
                conf_text = f"{confidence:.1%}"
                icon = "üü¢" if confidence > 0.8 else "üü°" if confidence > 0.6 else "üî¥"
                response += f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–ê–õ–ò–ó–ê:\n"
                response += "‚îÄ" * 30 + "\n"
                response += f"{name}:\n"
                response += f"  {label}\n"
                response += f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf_text} {icon}\n"
                break
    else:
        ensemble_result = [r for r in results if r[0] == "üèÜ –ê–Ω—Å–∞–º–±–ª—å"]
        if ensemble_result:
            name, class_idx, confidence, _ = ensemble_result[0]
            label = labels[class_idx]
            conf_text = f"{confidence:.1%}"
            icon = "üü¢" if confidence > 0.8 else "üü°" if confidence > 0.5 else "üî¥"
            response += f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–ê–õ–ò–ó–ê:\n"
            response += "‚îÄ" * 30 + "\n"
            response += "ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–∞–Ω—Å–∞–º–±–ª—å):\n"
            response += f"  {label}\n"
            response += f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf_text} {icon}\n"
    return response

async def start(update: Update, context: CallbackContext):
    keyboard = [
        ['üî¨ –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞'],
        ['üéØ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π (HOG+SVM)', 'üß† –ù–µ–π—Ä–æ—Å–µ—Ç—å (CNN)'],
        ['‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN', 'üöÄ –í—Å–µ 3 –º–æ–¥–µ–ª–∏'],
        ['üì∏ –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ']
    ]
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
    welcome_text = """
üëã Face Mask Detection Bot

ü§ñ 3 –º–µ—Ç–æ–¥–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–∫–∏:
1. üéØ HOG+SVM (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π, –±—ã—Å—Ç—Ä—ã–π)
2. üß† CNN (–Ω–µ–π—Ä–æ—Å–µ—Ç—å, —Ç–æ—á–Ω—ã–π) 
3. ‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN (–±–∞–ª–∞–Ω—Å)

üì∏ –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –ª–∏—Ü–∞:
"""
    await update.message.reply_text(welcome_text, reply_markup=reply_markup)

async def analyze_data(update: Update, context: CallbackContext):
    analysis_text = """
üìä –ê–ù–ê–õ–ò–ó –î–ê–¢–ê–°–ï–¢–ê:
‚Ä¢ –†–∞–∑–º–µ—Ä: ~12,000 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
‚Ä¢ –ö–ª–∞—Å—Å—ã: WithMask (50%), WithoutMask (50%)
‚Ä¢ –ë–∞–ª–∞–Ω—Å: –ò–î–ï–ê–õ–¨–ù–´–ô
‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ: –í–´–°–û–ö–û–ï
‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: 3 –º–æ–¥–µ–ª–∏
"""
    await update.message.reply_text(analysis_text)

async def handle_method_selection(update: Update, context: CallbackContext):
    method = update.message.text
    context.user_data['selected_method'] = method
    responses = {
        'üéØ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π (HOG+SVM)': "‚úÖ –í—ã–±—Ä–∞–Ω HOG+SVM (–±—ã—Å—Ç—Ä—ã–π). –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ.",
        'üß† –ù–µ–π—Ä–æ—Å–µ—Ç—å (CNN)': "‚úÖ –í—ã–±—Ä–∞–Ω–∞ CNN (—Ç–æ—á–Ω–∞—è). –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ.",
        '‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN': "‚úÖ –í—ã–±—Ä–∞–Ω–∞ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ.",
        'üöÄ –í—Å–µ 3 –º–æ–¥–µ–ª–∏': "üöÄ –í—ã–±—Ä–∞–Ω—ã –í–°–ï 3 –º–æ–¥–µ–ª–∏. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.",
        'üì∏ –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ': "üì∏ –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –ª–∏—Ü–∞."
    }
    if method in responses and responses[method]:
        await update.message.reply_text(responses[method])

async def handle_photo(update: Update, context: CallbackContext):
    try:
        processing_msg = await update.message.reply_text("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ...")
        photo_file = await update.message.photo[-1].get_file()
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp:
            await photo_file.download_to_drive(tmp.name)
            image = Image.open(tmp.name).convert('RGB')
            temp_path = tmp.name
        image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        quality_ok, quality_msg, metrics = check_image_quality(image_cv)
        quality_warning = ""
        if not quality_ok:
            quality_warning = "\n‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ –Ω–∏–∑–∫–æ–µ, —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–Ω–∏–∂–µ–Ω–∞."
        selected_method = context.user_data.get('selected_method', None)
        gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))
        if len(faces) == 0:
            await processing_msg.delete()
            await update.message.reply_text("‚ùå –õ–∏—Ü–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —á—ë—Ç–∫–æ–µ —Ñ–æ—Ç–æ —Å –ª–∏—Ü–æ–º.")
            os.unlink(temp_path)
            return
        faces = sorted(faces, key=lambda x: x[2]*x[3], reverse=True)
        x, y, w, h = faces[0]
        padding = 20
        x1, y1 = max(0, x-padding), max(0, y-padding)
        x2, y2 = min(image_cv.shape[1], x+w+padding), min(image_cv.shape[0], y+h+padding)
        face_roi = image.crop((x1, y1, x2, y2))
        results = ensemble_predict(face_roi, selected_method)
        full_response = format_results(results, selected_method)
        if quality_warning:
            full_response += quality_warning
        if len(faces) > 1:
            full_response += "\n" + "‚îÄ" * 30 + "\n"
            full_response += f"‚ÑπÔ∏è –ù–∞ —Ñ–æ—Ç–æ –Ω–∞–π–¥–µ–Ω–æ {len(faces)} –ª–∏—Ü. –ê–Ω–∞–ª–∏–∑ —Å–∞–º–æ–≥–æ –∫—Ä—É–ø–Ω–æ–≥–æ."
        for (fx, fy, fw, fh) in faces[:3]:
            cv2.rectangle(image_cv, (fx, fy), (fx+fw, fy+fh), (0, 255, 0), 2)
        processed_image = image_cv
        await processing_msg.delete()
        with tempfile.NamedTemporaryFile(suffix='_processed.jpg', delete=False) as tmp_proc:
            cv2.imwrite(tmp_proc.name, processed_image)
            with open(tmp_proc.name, 'rb') as photo:
                await update.message.reply_photo(photo, caption=full_response)
            os.unlink(tmp_proc.name)
        os.unlink(temp_path)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ: {e}", exc_info=True)
        try:
            await processing_msg.delete()
        except:
            pass
        for f in [temp_path, 'user_photo.jpg', 'processed.jpg']:
            try:
                if f and os.path.exists(f):
                    os.remove(f)
            except:
                pass

def main():
    TOKEN = "8230459480:AAHP99YpYbFRJ3IkTyImD1x8_i0_GKpvmwc"
    logging.basicConfig(
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        level=logging.INFO
    )
    application = Application.builder().token(TOKEN).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & filters.Regex('^üî¨ –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞$'), analyze_data))
    application.add_handler(MessageHandler(filters.TEXT & (
        filters.Regex('^üéØ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π') | 
        filters.Regex('^üß† –ù–µ–π—Ä–æ—Å–µ—Ç—å') | 
        filters.Regex('^‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è') |
        filters.Regex('^üöÄ –í—Å–µ 3 –º–æ–¥–µ–ª–∏') |
        filters.Regex('^üì∏ –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ')
    ), handle_method_selection))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    application.run_polling()

if __name__ == '__main__':
    main()